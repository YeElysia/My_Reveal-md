<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第七章: 深度网络基础组件 (详细资料)</title>
    <style>
        :root {
            --primary-color: #005f87; /* 浙大蓝 */
            --secondary-color: #f7f9fa;
            --font-color: #333;
            --border-color: #e0e0e0;
            --header-bg: #fff;
            --nav-width: 260px; /* 导航栏宽度 */
            --accent-color: #d9534f;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif;
            line-height: 1.8;
            color: var(--font-color);
            background-color: var(--secondary-color);
            margin: 0;
            padding: 0;
        }
        .vertical-navbar {
            position: fixed;
            top: 0;
            left: 0;
            width: var(--nav-width);
            height: 100vh;
            background-color: var(--header-bg);
            box-shadow: 2px 0 5px rgba(0,0,0,0.05);
            padding-top: 20px;
            overflow-y: auto;
            z-index: 1000;
        }
        .vertical-navbar .nav-header {
            padding: 10px 20px 20px 20px;
            font-weight: bold;
            font-size: 1.4em;
            color: var(--primary-color);
            text-align: center;
        }
        .vertical-navbar .nav-header a {
            text-decoration: none;
            color: var(--accent-color);
        }
        .vertical-navbar a {
            display: block;
            padding: 12px 20px;
            text-decoration: none;
            color: var(--font-color);
            transition: background-color 0.3s;
            border-left: 3px solid transparent;
        }
        .vertical-navbar a:hover {
            background-color: var(--secondary-color);
        }
        .vertical-navbar a.active {
            font-weight: bold;
            color: var(--primary-color);
            border-left-color: var(--primary-color);
            background-color: #eaf2f5;
        }
        .main-content {
            margin-left: var(--nav-width);
            padding: 20px 40px;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        h1, h2, h3, h4 {
            color: var(--primary-color);
            border-bottom: 2px solid var(--primary-color);
            padding-bottom: 10px;
            margin-bottom: 20px;
        }
        h1 {
            text-align: center;
            border-bottom: none;
            margin-top: 0;
        }
        .collapsible {
            cursor: pointer;
            border: 1px solid var(--border-color);
            border-radius: 5px;
            padding: 15px 20px;
            margin-top: 15px;
            transition: background-color 0.3s;
            background-color: #fff;
            position: relative;
        }
        .collapsible h2 {
            margin: 0;
            padding: 0;
            border: none;
            color: var(--primary-color);
            font-size: 1.2em;
        }
        .collapsible::after {
            content: '\\25BC'; /* Down arrow */
            position: absolute;
            right: 20px;
            top: 50%;
            transform: translateY(-50%);
            transition: transform 0.3s;
            color: #888;
            font-size: 0.8em;
        }
        .collapsible.active::after {
            transform: translateY(-50%) rotate(180deg);
        }
        .content {
            padding: 20px;
            display: none;
            overflow: hidden;
            border: 1px solid var(--border-color);
            border-top: none;
            border-radius: 0 0 5px 5px;
            background-color: #fdfdfd;
        }
        .collapsible:hover {
            background-color: #f0f5f8;
        }
        .key-term {
            color: var(--accent-color);
            font-weight: bold;
        }
        .img-placeholder {
            border: 2px dashed var(--border-color);
            padding: 40px;
            text-align: center;
            color: #888;
            margin: 20px 0;
            border-radius: 5px;
            background-color: #fafafa;
        }
        ul, ol {
            padding-left: 25px;
        }
    </style>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
</head>
<body>

    <nav class="vertical-navbar">
        <div class="nav-header">
            <a href="index.html">考前冲刺主页</a>
        </div>
        <a href="chapter_01.html">Ch1-导论</a>
        <a href="chapter_02.html">Ch2-系统基础</a>
        <a href="chapter_03.html">Ch3-开发基础</a>
        <a href="chapter_04.html">Ch4-问题求解</a>
        <a href="chapter_05.html">Ch5-回归与分类</a>
        <a href="chapter_06.html">Ch6-聚类与降维</a>
        <a href="chapter_07.html" class="active">Ch7-深度网络</a>
        <a href="chapter_08.html">Ch8-CNN</a>
        <a href="chapter_09.html">Ch9-RNN</a>
        <a href="chapter_10.html">Ch10-综合实践</a>
        <a href="chapter_11.html">Ch11-NLP</a>
        <a href="chapter_12.html">Ch12-LLM</a>
        <a href="chapter_13.html">Ch13-多模态</a>
        <a href="index.html#code-appendix">常用代码速查</a>
    </nav>

    <main class="main-content">
        <div class="container">
            <h1>第七章: 深度网络基础组件 (详细资料)</h1>

            <div class="collapsible" id="kp-deep-learning-overview">
                <h2>7.1 深度学习概述</h2>
            </div>
            <div class="content">
                <p>深度学习（Deep Learning, DL）是机器学习的一个重要分支，它使用包含多个处理层的<span class="key-term">人工神经网络</span>来学习数据的表示。这里的“深”指的是网络具有多个隐藏层。</p>
                <h4>深度学习的特征</h4>
                <ul>
                    <li><strong>多层网络结构</strong>：由输入层、多个隐藏层和输出层组成，能够学习从低级到高级的<span class="key-term">层次化特征</span>。</li>
                    <li><strong>自动特征提取</strong>：与传统机器学习需要手动设计特征（特征工程）不同，深度学习能自动从原始数据中学习有用的特征。</li>
                    <li><strong>非线性处理能力</strong>：通过使用<span class="key-term">非线性激活函数</span>，深度网络能够学习和表示复杂的非线性关系。</li>
                    <li><strong>大规模数据处理能力</strong>：深度学习模型通常参数众多，需要大量数据进行训练才能发挥其强大性能，并受益于现代计算硬件（如GPU）的发展。</li>
                </ul>
            </div>

            <div class="collapsible" id="kp-perceptron-model">
                <h2>7.2 感知机模型 (Perceptron)</h2>
            </div>
            <div class="content">
                <p>感知机是神经网络的最基本单元，是对生物神经元（M-P模型）的数学建模。</p>
                <div class="img-placeholder">[此处应插入图片：M-P神经元模型图，见课件第 284 页]</div>
                <h4>感知机结构与公式</h4>
                <p>一个感知机接收多个输入信号（$x_1, x_2, \dots$），每个信号乘以一个对应的权重（$w_1, w_2, \dots$）。然后，将所有加权后的输入求和，并加上一个偏置项 $b$。最后，这个结果通过一个<span class="key-term">激活函数</span> $f$ 处理，得到最终的输出 $y$。</p>
                <p>数学公式为：$y = f(\sum_{i} w_i x_i + b) = f(\mathbf{w}^T\mathbf{x} + b)$</p>
                
                <h4>感知机的局限性</h4>
                <p>单个感知机本质上是一个线性分类器。它只能解决<span class="key-term">线性可分</span>的问题，即能够用一条直线（或一个超平面）将两类数据点完全分开的问题。对于<span class="key-term">线性不可分</span>的问题，如经典的<span class="key-term">“异或”（XOR）问题</span>，单个感知机无法求解。这一局限性在1969年被马文·明斯基证明，直接导致了神经网络研究的第一次低谷。</p>
                <div class="img-placeholder">[此处应插入图片：异或问题的线性不可分示意图，见课件第 293 页]</div>
            </div>

            <div class="collapsible" id="kp-activation-functions">
                <h2>7.3 激活函数 (Activation Functions)</h2>
            </div>
            <div class="content">
                <p>激活函数是神经网络的核心组件，其主要作用是为网络引入<span class="key-term">非线性</span>因素。如果没有激活函数，或者激活函数是线性的，那么无论神经网络有多少层，其本质都等同于一个单层的线性模型，无法学习复杂的模式。</p>
                <div class="img-placeholder">[此处应插入图片：常用激活函数（Sigmoid, Tanh, ReLU）的图像对比，见课件第 286-289 页]</div>
                <h4>常用激活函数</h4>
                <ul>
                    <li><strong>Sigmoid</strong>：函数形式为 $\sigma(x) = \frac{1}{1+e^{-x}}$。它将任意实数压缩到 (0, 1) 区间，常用于二分类任务的输出层，表示概率。缺点是容易导致梯度消失，且输出不是零中心的。</li>
                    <li><strong>Tanh (双曲正切)</strong>：将任意实数压缩到 (-1, 1) 区间。相比Sigmoid，它的输出是零中心的，收敛速度通常更快，但仍存在梯度消失问题。</li>
                    <li><span class="key-term">ReLU (Rectified Linear Unit)</span>：函数形式为 $f(x) = \max(0, x)$。它是目前深度学习中<span class="key-term">隐藏层最常用</span>的激活函数。
                        <ul>
                            <li><strong>优点</strong>：计算非常简单高效；在正数区间不会饱和，有效缓解了梯度消失问题。</li>
                            <li><strong>缺点</strong>：输出不是零中心；可能导致“神经元死亡”（Dying ReLU），即某些神经元可能永远不会被激活。</li>
                        </ul>
                    </li>
                    <li><span class="key-term">Softmax</span>：它不是作用于单个神经元，而是作用于整个输出层。它能将一个向量的原始分数值（logits）转换为一个<span class="key-term">概率分布</span>，其中每个元素都在 (0, 1) 之间，且所有元素之和为1。因此，它专门用于<span class="key-term">多分类任务的输出层</span>。</li>
                </ul>
            </div>
            
            <div class="collapsible" id="kp-loss-and-bp">
                <h2>7.4/7.5/7.6 损失函数、优化器与BP算法</h2>
            </div>
            <div class="content">
                <p>这三者是驱动神经网络学习的核心机制。</p>
                <h4>损失函数 (Loss Function)</h4>
                <p>损失函数用于量化模型<span class="key-term">预测值与真实值之间的差距</span>。训练的目标就是通过调整网络参数（权重和偏置）来最小化损失函数的值。</p>
                <ul>
                    <li><strong>均方误差 (MSE)</strong>：$L = \frac{1}{n}\sum(y_{true} - y_{pred})^2$。常用于<span class="key-term">回归</span>任务。</li>
                    <li><strong>交叉熵损失 (Cross-Entropy Loss)</strong>：衡量两个概率分布的差异，是<span class="key-term">分类</span>任务的标准损失函数。对于多分类任务，通常与Softmax激活函数配合使用。</li>
                </ul>

                <h4>优化器与梯度下降 (Optimizer & Gradient Descent)</h4>
                <p>优化器的作用是根据损失函数计算出的梯度，来更新网络的参数。</p>
                <ul>
                    <li><strong>梯度下降法</strong>：最基本的优化算法。它计算损失函数对所有参数的梯度，然后沿着梯度的<span class="key-term">负方向</span>按一定步长（学习率）更新参数，以寻找损失函数的最小值。</li>
                    <li><strong>学习率 (Learning Rate)</strong>：控制每次参数更新的幅度。设置过大可能导致模型在最优点附近震荡无法收敛；设置过小则收敛速度过慢。</li>
                    <li><strong>常用优化器</strong>：
                        <ul>
                            <li><strong>SGD (随机梯度下降)</strong>：每次只用一小批(mini-batch)数据计算梯度来更新，大大提高了训练效率。</li>
                            <li><span class="key-term">Adam</span>：结合了动量和自适应学习率的优点，能够为不同参数自动调整学习率，通常收敛速度更快、更稳定，是目前最常用的优化器之一。</li>
                        </ul>
                    </li>
                </ul>

                <h4>误差反向传播算法 (BP Algorithm)</h4>
                <p>BP算法是成功训练多层神经网络的关键，它解决了如何高效计算深层网络中每个参数的梯度的问题。</p>
                <p><strong>过程</strong>：</p>
                <ol>
                    <li><strong>前向传播 (Forward Propagation)</strong>：将输入数据从输入层开始，逐层向前计算，直到得到输出层的预测结果。</li>
                    <li><strong>计算损失 (Compute Loss)</strong>：将预测结果与真实标签进行比较，计算损失值。</li>
                    <li><strong>反向传播 (Backward Propagation)</strong>：这是BP算法的核心。利用微积分中的<span class="key-term">链式法则</span>，从输出层开始，逐层向后计算损失函数对每一层参数（权重和偏置）的偏导数（即梯度）。</li>
                    <li><strong>参数更新 (Update Parameters)</strong>：使用优化器（如梯度下降）根据计算出的梯度来更新网络中的所有参数。</li>
                </ol>
                <p><strong>局限性</strong>：</p>
                <ul>
                    <li>容易陷入<span class="key-term">局部最小值</span>而非全局最优。</li>
                    <li>收敛速度可能较慢。</li>
                    <li>隐藏层的结构（层数、神经元数）缺乏理论指导，需要大量实验。</li>
                    <li>存在“灾难性遗忘”问题，即学习新知识时可能会覆盖掉旧知识。</li>
                </ul>
            </div>
        </div>
    </main>

    <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const collapsibles = document.querySelectorAll(".collapsible");
            collapsibles.forEach(coll => {
                coll.addEventListener("click", function() {
                    this.classList.toggle("active");
                    const content = this.nextElementSibling;
                    if (content.style.display === "block") {
                        content.style.display = "none";
                    } else {
                        content.style.display = "block";
                    }
                });
            });
            
            // KaTeX rendering
            if (typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: "$$", right: "$$", display: true},
                        {left: "$", right: "$", display: false}
                    ]
                });
            }
        });
    </script>

</body>
</html>